{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e783304",
   "metadata": {},
   "source": [
    "1. Build a Classification Model with Spark with a dataset of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62acaec",
   "metadata": {},
   "source": [
    "Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1df3f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ClassificationModel\") \\\n",
    "        .getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    print(\"Spark session initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Spark session: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039efa5b",
   "metadata": {},
   "source": [
    "Load Dataset (Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16450b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+-----+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|label|\n",
      "+-----------------+----------------+-----------------+----------------+-----+\n",
      "|              5.1|             3.5|              1.4|             0.2|    0|\n",
      "|              4.9|             3.0|              1.4|             0.2|    0|\n",
      "|              4.7|             3.2|              1.3|             0.2|    0|\n",
      "|              4.6|             3.1|              1.5|             0.2|    0|\n",
      "|              5.0|             3.6|              1.4|             0.2|    0|\n",
      "+-----------------+----------------+-----------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "df = spark.createDataFrame(iris_df)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e0622",
   "metadata": {},
   "source": [
    "Data Preprocessing (Vector Assembler + Label Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ff89c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|    0|\n",
      "|[4.9,3.0,1.4,0.2]|    0|\n",
      "|[4.7,3.2,1.3,0.2]|    0|\n",
      "|[4.6,3.1,1.5,0.2]|    0|\n",
      "|[5.0,3.6,1.4,0.2]|    0|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "feature_cols = iris.feature_names\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df).select(\"features\", \"label\")\n",
    "df_assembled.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8daac3",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f233ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_assembled.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2576ae",
   "metadata": {},
   "source": [
    "Train Classification Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e13d119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe7cd4",
   "metadata": {},
   "source": [
    "Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f38e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+----------+\n",
      "|         features|label|prediction|\n",
      "+-----------------+-----+----------+\n",
      "|[4.6,3.1,1.5,0.2]|    0|       0.0|\n",
      "|[4.8,3.4,1.6,0.2]|    0|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|    0|       0.0|\n",
      "|[5.4,3.7,1.5,0.2]|    0|       0.0|\n",
      "|[4.6,3.6,1.0,0.2]|    0|       0.0|\n",
      "|[5.0,3.0,1.6,0.2]|    0|       0.0|\n",
      "|[5.0,3.2,1.2,0.2]|    0|       0.0|\n",
      "|[5.4,3.4,1.5,0.4]|    0|       0.0|\n",
      "|[4.4,3.2,1.3,0.2]|    0|       0.0|\n",
      "|[5.0,3.5,1.3,0.3]|    0|       0.0|\n",
      "|[5.1,3.4,1.5,0.2]|    0|       0.0|\n",
      "|[5.1,3.8,1.6,0.2]|    0|       0.0|\n",
      "|[5.1,3.8,1.9,0.4]|    0|       0.0|\n",
      "|[5.9,3.0,4.2,1.5]|    1|       1.0|\n",
      "|[5.8,2.7,3.9,1.2]|    1|       1.0|\n",
      "|[6.8,2.8,4.8,1.4]|    1|       1.0|\n",
      "|[5.1,2.5,3.0,1.1]|    1|       1.0|\n",
      "|[5.7,2.8,4.1,1.3]|    1|       1.0|\n",
      "|[5.7,3.0,4.2,1.2]|    1|       1.0|\n",
      "|[5.8,2.6,4.0,1.2]|    1|       1.0|\n",
      "+-----------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_data)\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e383e",
   "metadata": {},
   "source": [
    "Accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f1c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f53b61",
   "metadata": {},
   "source": [
    "Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e3de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
